{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Creating Synthetic Dataset for Document Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "sys.path.append('..' + os.sep)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np \n",
    "\n",
    "from src.models.unet import UNet\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import shutil \n",
    "import random \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assembling Document Images**\n",
    "\n",
    "In my research, I could not more/ reliable data sources for documents in context. or real world images of documents with a wide variety of different perspectives / lighting / backgrounds. So we assemble a synthetic dataset comprised of document images from OCR / denoising / binarization datasets, superimposed and augmented onto backgrounds aggregated from google images. \n",
    "\n",
    "In total, we will have 4,363 images compiled from the following datasets: \n",
    "| Dataset Name                                                                 | Number of Images | Format | Size      | \n",
    "|------------------------------------------------------------------------------|------------------|--------|-----------|\n",
    "| [LRDE Document Binarization Dataset](https://www.lrde.epita.fr/wiki/Olena/DatasetDBD#Data) | 125 | png    | 2516x3712 |\n",
    "| [FUNSD: Form Understanding in Noisy Scanned Docs](https://guillaumejaume.github.io/FUNSD/)  | 199 | png    | 754x1000 |\n",
    "| [IAM Handwritten Forms Dataset](https://www.kaggle.com/datasets/naderabdalghani/iam-handwritten-forms-dataset?select=data) | 1,539 | png | 2479x3542 |\n",
    "| [DocVA: Document Collection VQA](https://www.docvqa.org/datasets/doccvqa) | 12,768 (only using 1,000) | png | 1682x2159 | \n",
    "| [The DocBank Dataset (Part 1)](https://doc-analysis.github.io/docbank-page/index.html) | 54,984 (only using 1,500) | jpg | 773x1000 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO SAMPLES FROM EACH DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO AGG$REGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First \n",
    "QUERIES = [\n",
    "    \"table images top view\",\n",
    "    \"wooden table texture\",\n",
    "    \"marble texture\",\n",
    "    \"carpet texture\",\n",
    "    \"concrete wall texture\",\n",
    "    \"whiteboard background\",\n",
    "    \"brick wall texture\",\n",
    "    \"office desk top view\",\n",
    "    \"linen tablecloth texture background\",\n",
    "    \"leather texture\",\n",
    "    \"metal surface texture\",\n",
    "    \"table images top view\",\n",
    "    \"sidewalk top view\",\n",
    "    \"sand texture\",\n",
    "    \"grass field top view\",\n",
    "    \"stone pavement texture\",\n",
    "    \"wooden deck texture\",\n",
    "    \"forest floor texture\",\n",
    "    \"rock surface texture\",\n",
    "    \"colorful backgrounds\",\n",
    "    \"colorful desk background\",\n",
    "    \"dark desk background\",\n",
    "    \"light desk background\",\n",
    "    \"floor texture\"\n",
    "    ]\n",
    "\n",
    "USER_AGENT = (\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    ")\n",
    "HEADERS = {\n",
    "    \"User-Agent\": USER_AGENT\n",
    "}\n",
    "\n",
    "\n",
    "def fetch_image_urls(query: str, max_links: int) -> list:\n",
    "    search_url = f\"https://www.google.com/search?site=&tbm=isch&q={query}\"\n",
    "    response = requests.get(search_url, headers=HEADERS)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error: {response.status_code}\")\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Trying an alternate way to fetch the image urls\n",
    "    img_tags = soup.select('.rg_i.Q4LuWd')\n",
    "    img_urls = [img.get('data-src') or img.get('data-iurl') for img in img_tags]\n",
    "    img_urls = [url for url in img_urls if url is not None and url.startswith(('http:', 'https:'))]\n",
    "\n",
    "    return img_urls[:max_links]\n",
    "\n",
    "\n",
    "def download_images_from_query(queries: list, max_images_per_query: int):\n",
    "    for query in queries:\n",
    "        img_urls = fetch_image_urls(query, max_images_per_query)\n",
    "        for i, url in enumerate(img_urls):\n",
    "            response = requests.get(url)\n",
    "            filename = os.path.join(\"..\",\"data\",\"documents\",\"google\", f\"{query.replace(' ', '_')}_{i + 1}.jpg\")\n",
    "            with open(filename, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "download_images_from_query(QUERIES, 100)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 1000 images from ..\\data\\documents\\raw\\DocBank_500K_ori_img.zip\\images to ..\\data\\documents\\raw\\DocBank_500K_ori_img.zip\\sample.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "source = os.path.join(\"..\",\"data\",\"documents\",\"raw\",\"DocBank_500K_ori_img.zip\",\"images\")\n",
    "dest =  os.path.join(\"..\",\"data\",\"documents\",\"raw\",\"DocBank_500K_ori_img.zip\",\"sample\")\n",
    "\n",
    "\n",
    "if not os.path.exists(source):\n",
    "    raise ValueError(f\"Source directory {source} does not exist.\")\n",
    "\n",
    "# Get a list of all images in the source directory\n",
    "all_images = [f for f in os.listdir(source) if os.path.isfile(os.path.join(source, f))]\n",
    "\n",
    "\n",
    "# Randomly sample images\n",
    "sampled_images = random.sample(all_images, 1500)\n",
    "\n",
    "# Create destination directory if it doesn't exist\n",
    "if not os.path.exists(dest):\n",
    "    os.makedirs(dest)\n",
    "\n",
    "# Copy the sampled images to the destination directory\n",
    "for image in sampled_images:\n",
    "    shutil.copy2(os.path.join(source, image), os.path.join(dest, image))\n",
    "print(f\"Copied {1000} images from {source} to {dest}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1343/1343 [00:16<00:00, 79.81it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dirPath = \"E:\\\\GitHub\\\\docUNET-Pytorch\\\\data\\\\document_dataset_resized\\\\valid\\\\images\"\n",
    "files = os.listdir(dirPath)\n",
    "SIZE = (312,312)\n",
    "\n",
    "\n",
    "for f in tqdm(files): \n",
    "    fpath = os.path.join(dirPath,f)\n",
    "    img = cv2.imread(fpath)\n",
    "    resized = cv2.resize(img,SIZE,cv2.INTER_NEAREST)\n",
    "    #plt.imshow(resized)\n",
    "    cv2.imwrite(fpath,resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
